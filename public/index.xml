<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hidden Layer</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Hidden Layer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 19 May 2025 17:30:00 -0300</lastBuildDate><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Weekly – May 19, 2025</title>
      <link>http://localhost:1313/ai-llm-news/ai-weekly-may-13-2025/</link>
      <pubDate>Mon, 19 May 2025 17:30:00 -0300</pubDate>
      
      <guid>http://localhost:1313/ai-llm-news/ai-weekly-may-13-2025/</guid>
      <description>
        
          
            &lt;p&gt;This week, the AI landscape witnessed significant advancements, from major tech conferences unveiling new AI tools to groundbreaking infrastructure projects in space.&lt;/p&gt;
&lt;h2 id=&#34;1-microsoft-embraces-the-agentic-web-at-build-2025&#34;&gt;1. Microsoft Embraces the &amp;lsquo;Agentic Web&amp;rsquo; at Build 2025&lt;/h2&gt;




&lt;figure class=&#34;blog-figure&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/images/ai-weekly-may-19-2025_01.png&#34; alt=&#34;Microsoft Build 2025&#34; class=&#34;blog-image&#34; loading=&#34;lazy&#34;&gt;
    
&lt;/figure&gt;

&lt;p&gt;At the Build 2025 conference, Microsoft introduced its vision for an &amp;ldquo;open agentic web,&amp;rdquo; emphasizing AI agents capable of performing tasks autonomously. Key announcements included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GitHub Copilot Enhancements&lt;/strong&gt;: New features allow developers to streamline coding tasks with improved AI assistance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integration of Third-Party Models&lt;/strong&gt;: Microsoft&amp;rsquo;s Azure will host AI models from partners like xAI, Meta, Mistral, and Black Forest Labs, expanding the diversity of AI tools available to developers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NLWeb Project&lt;/strong&gt;: An initiative aimed at simplifying the development of AI-powered natural language web interfaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These developments underscore Microsoft&amp;rsquo;s commitment to fostering an ecosystem where AI agents can operate seamlessly across platforms. (&lt;a href=&#34;https://blogs.microsoft.com/blog/2025/05/19/microsoft-build-2025-the-age-of-ai-agents-and-building-the-open-agentic-web/?utm_source=chatgpt.com&#34;&gt;blogs.microsoft.com&lt;/a&gt;)&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>The Irresistible Temptation of a New LLM</title>
      <link>http://localhost:1313/memes/ai-engineer-meme_03/</link>
      <pubDate>Fri, 16 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/memes/ai-engineer-meme_03/</guid>
      <description>
        
          
            &lt;h1 id=&#34;when-a-new-llm-drops-and-your-production-model-cries&#34;&gt;When a new LLM drops and your production model cries&lt;/h1&gt;




&lt;figure class=&#34;blog-figure&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/images/ai_meme_03.png&#34; alt=&#34;LLM temptation meme&#34; class=&#34;blog-image&#34; loading=&#34;lazy&#34;&gt;
    
&lt;/figure&gt;

&lt;p&gt;There’s a stable, well-tested, production-ready model.&lt;br&gt;
It went through weeks of fine-tuning.&lt;br&gt;
It has guardrails. It logs. It scales.&lt;/p&gt;
&lt;p&gt;But then&amp;hellip;&lt;br&gt;
🚨 &lt;em&gt;New LLM just dropped on HuggingFace with +0.3 on MMLU&lt;/em&gt; 🚨&lt;/p&gt;
&lt;p&gt;And suddenly, you’re that guy.&lt;br&gt;
The one you swore you’d never become.&lt;br&gt;
Again.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-real-job&#34;&gt;The real job&lt;/h2&gt;
&lt;p&gt;Being an AI Engineer isn’t just &amp;ldquo;prompt + deploy&amp;rdquo;.&lt;br&gt;
It’s tradeoffs. It’s reliability.&lt;br&gt;
It’s monitoring a hallucination spike at 2AM because someone tried to replace your model mid-sprint.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Your First Kaggle Challenge: CRISP-DM in Action</title>
      <link>http://localhost:1313/kaggle/second-step-on-kaggle/</link>
      <pubDate>Wed, 14 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/kaggle/second-step-on-kaggle/</guid>
      <description>
        
          
            &lt;figure class=&#34;blog-figure&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/images/titanic.png&#34; alt=&#34;Titanic Logo&#34; class=&#34;blog-image&#34; loading=&#34;lazy&#34;&gt;
    
&lt;/figure&gt;

&lt;p&gt;Welcome to our &lt;strong&gt;Kaggle journey&lt;/strong&gt;! If you&amp;rsquo;re curious about AI and machine learning but feel a bit overwhelmed, you&amp;rsquo;re in the right place. Think of Kaggle as your friendly neighborhood playground for data science: a place where you can learn, experiment, and grow alongside a supportive community.&lt;/p&gt;
&lt;p&gt;This is the second step, if you&amp;rsquo;re following along, you should have already completed the first step, which is to &lt;a href=&#34;https://www.kaggle.com/account/login&#34;&gt;First Steps on Kaggle: a friendly guide to getting started with Practical AI&lt;/a&gt;.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
      <link>http://localhost:1313/papers/bert/</link>
      <pubDate>Tue, 13 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/papers/bert/</guid>
      <description>
        
          
            &lt;h1 id=&#34;bert&#34;&gt;BERT&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt;: Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova
&lt;strong&gt;Publication Date&lt;/strong&gt;: May 24, 2019&lt;br&gt;
&lt;strong&gt;Published In&lt;/strong&gt;: arXiv&lt;br&gt;
&lt;strong&gt;Number of Citations&lt;/strong&gt;: Highly cited (exact number varies)
&lt;strong&gt;Link to Paper&lt;/strong&gt;: &lt;a href=&#34;https://arxiv.org/abs/1810.04805&#34;&gt;arXiv.org/attention&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#brief-description&#34;&gt;Brief Description&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#main-topic&#34;&gt;Main Topic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#key-concepts&#34;&gt;Key Concepts&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#1-bidirectional-transformers&#34;&gt;1. Bidirectional Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#2-masked-language-modeling-mlm&#34;&gt;2. Masked Language Modeling (MLM)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#3-next-sentence-prediction-nsp&#34;&gt;3. Next Sentence Prediction (NSP)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#methodology-and-experiments&#34;&gt;Methodology and Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#references-and-related-work&#34;&gt;References and Related Work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#conclusion-and-takeaways&#34;&gt;Conclusion and Takeaways&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#key-takeaways&#34;&gt;Key Takeaways&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#why-this-paper-still-matters&#34;&gt;Why This Paper Still Matters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/bert/#thanks-for-reading&#34;&gt;Thanks for Reading&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;brief-description&#34;&gt;Brief Description&lt;/h2&gt;
&lt;p&gt;BERT (Bidirectional Encoder Representations from Transformers) is a language representation model developed by researchers at Google. Unlike previous models, BERT leverages deep bidirectional transformers, capturing context from both directions (left-to-right and right-to-left), significantly enhancing natural language understanding capabilities.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>AI Weekly – May 12, 2025</title>
      <link>http://localhost:1313/ai-llm-news/ai-weekly-may-12-2025/</link>
      <pubDate>Mon, 12 May 2025 16:13:43 -0300</pubDate>
      
      <guid>http://localhost:1313/ai-llm-news/ai-weekly-may-12-2025/</guid>
      <description>
        
          
            &lt;p&gt;This week’s AI roundup highlights the accelerating disruption caused by large language models and autonomous agents, from surging startup valuations to major layoffs and delayed infrastructure bets.&lt;/p&gt;
&lt;h2 id=&#34;-summary&#34;&gt;📌 Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/ai-llm-news/ai-weekly-may-12-2025/#1-perplexity-valued-at-14-billion-in-new-funding-round&#34;&gt;&lt;strong&gt;Perplexity&lt;/strong&gt; raises valuation to $14B and plans a browser launch&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/ai-llm-news/ai-weekly-may-12-2025/#2-chegg-lays-off-22-amid-ai-disruption-in-edtech&#34;&gt;&lt;strong&gt;Chegg&lt;/strong&gt; lays off nearly a quarter of its workforce due to AI-driven disruption&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/ai-llm-news/ai-weekly-may-12-2025/#3-google-launches-ai-futures-fund-for-startups&#34;&gt;&lt;strong&gt;Google&lt;/strong&gt; announces AI Futures Fund to empower next-gen startups&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/ai-llm-news/ai-weekly-may-12-2025/#4-100-billion-openaisoftbank-stargate-project-delayed&#34;&gt;&lt;strong&gt;OpenAI &amp;amp; SoftBank&lt;/strong&gt; hit delays on their $100B Stargate project&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-perplexity-valued-at-14-billion-in-new-funding-round&#34;&gt;1. Perplexity Valued at $14 Billion in New Funding Round&lt;/h2&gt;




&lt;figure class=&#34;blog-figure&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/images/ai-weekly-may-12-2025_01.png&#34; alt=&#34;Perplexity&amp;#39;s rising valuation&#34; class=&#34;blog-image&#34; loading=&#34;lazy&#34;&gt;
    
&lt;/figure&gt;

&lt;p&gt;AI search startup &lt;a href=&#34;http://perplexity.ai/&#34;&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;&lt;/a&gt; is closing a fresh funding round that values the company at $14 billion, up more than 50% since November 2024. The company is also working on launching its own browser, &lt;strong&gt;Comet&lt;/strong&gt;, which could directly challenge Chrome and Safari.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deployino Fatalino: The Spirit of Friday 5PM Deploys</title>
      <link>http://localhost:1313/memes/deployino-fatalino-meme/</link>
      <pubDate>Fri, 09 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/memes/deployino-fatalino-meme/</guid>
      <description>
        
          
            &lt;h1 id=&#34;deployino-fatalino-the-spirit-of-friday-5pm-deploys&#34;&gt;Deployino Fatalino: the spirit of friday 5PM deploys&lt;/h1&gt;
&lt;div class=&#34;video-container&#34;&gt;
  &lt;video controls width=&#34;100%&#34; src=&#34;http://localhost:1313/videos/deployino_fatalino.mp4&#34;&gt;
    .
  &lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Deployino Fatalino. È venerdì, le diciassette.&lt;br&gt;
E Deployino fugge sulla bicicletta del disastro, con il caffè in testa e i container in fiamme.&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Deployino Fatalino. It is Friday, five o&amp;rsquo;clock PM.&lt;br&gt;
And Deployino flees the disaster on his bike, coffee on his head, and containers in flames.&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-problem-with-friday-deploys-especially-for-ai-engineers&#34;&gt;The Problem with Friday Deploys (Especially for AI Engineers)&lt;/h2&gt;
&lt;p&gt;Deploys on a Friday at 5PM are never just deploys.&lt;br&gt;
In AI systems, they&amp;rsquo;re &lt;strong&gt;multi-dimensional bets against entropy&lt;/strong&gt;.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>The AI Engineer Journey: A Modern Overview</title>
      <link>http://localhost:1313/become-an-ai-expert/ai-engineer-journey/</link>
      <pubDate>Thu, 08 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/become-an-ai-expert/ai-engineer-journey/</guid>
      <description>
        
          
            &lt;h1 id=&#34;the-ai-engineer-journey-a-modern-overview&#34;&gt;The AI Engineer Journey: A Modern Overview&lt;/h1&gt;




&lt;figure class=&#34;blog-figure&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/images/ai-engineer-journey.png&#34; alt=&#34;AI Engineer Journey&#34; class=&#34;blog-image&#34; loading=&#34;lazy&#34;&gt;
    
&lt;/figure&gt;

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#why-ai-engineering-now&#34;&gt;Why AI Engineering Now?&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#from-data-scientist-to-ai-engineer&#34;&gt;From Data Scientist to AI Engineer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#the-rise-of-systems-over-notebooks&#34;&gt;The Rise of Systems Over Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#why-engineering-matters-more-than-ever&#34;&gt;Why Engineering Matters More Than Ever&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#what-makes-ai-engineering-unique&#34;&gt;What Makes AI Engineering Unique?&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#you-design-systems-not-just-predictions&#34;&gt;You Design Systems, Not Just Predictions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#real-stories-code-bugs-and-architecture&#34;&gt;Real Stories, Code, Bugs, and Architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#key-pillars-of-ai-engineering-the-journey-ahead&#34;&gt;Key Pillars of AI Engineering&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#weekly-deep-dives-into-each-pillar&#34;&gt;Weekly Deep Dives into Each Pillar&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#a-practical-honest-path--not-a-buzzword-tour&#34;&gt;A Practical, Honest Path&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/become-an-ai-expert/ai-engineer-journey/#thanks-for-reading&#34;&gt;Thanks for Reading&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-ai-engineering-now&#34;&gt;Why AI Engineering Now?&lt;/h2&gt;
&lt;p&gt;The field of artificial intelligence has evolved rapidly — from academic research and isolated PoCs to full-scale systems powering real products. In this transition, a new role emerged: the AI Engineer. This isn’t just a rebranding of the Data Scientist or ML Engineer, but a natural response to the growing complexity of deploying, monitoring, and scaling AI systems in the wild. &lt;strong&gt;The world no longer needs just model accuracy, it needs models that ship.&lt;/strong&gt;&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>First Steps on Kaggle: a friendly guide to getting started with Practical AI</title>
      <link>http://localhost:1313/kaggle/first-steps-on-kaggle/</link>
      <pubDate>Wed, 07 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/kaggle/first-steps-on-kaggle/</guid>
      <description>
        
          
            &lt;figure class=&#34;blog-figure&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/images/kaggle-logo.png&#34; alt=&#34;Kaggle Logo&#34; class=&#34;blog-image&#34; loading=&#34;lazy&#34;&gt;
    
&lt;/figure&gt;

&lt;p&gt;Welcome to our &lt;strong&gt;Kaggle journey&lt;/strong&gt;! If you&amp;rsquo;re curious about AI and machine learning but feel a bit overwhelmed, you&amp;rsquo;re in the right place. Think of Kaggle as your friendly neighborhood playground for data science: a place where you can learn, experiment, and grow alongside a supportive community.&lt;/p&gt;
&lt;h2 id=&#34;what-is-kaggle&#34;&gt;What is Kaggle?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/&#34;&gt;&lt;strong&gt;Kaggle&lt;/strong&gt;&lt;/a&gt; is an online platform owned by Google that brings together data enthusiasts, AI engineers, and curious learners from around the world. It offers:&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Attention is All You Need: The Paper that Changed AI</title>
      <link>http://localhost:1313/papers/attention-is-all-you-need/</link>
      <pubDate>Tue, 06 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/papers/attention-is-all-you-need/</guid>
      <description>
        
          
            &lt;h1 id=&#34;attention-is-all-you-need&#34;&gt;Attention is All You Need&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt;: Ashish Vaswani, Noam Shazeer, Niki Parmar et al.&lt;br&gt;
&lt;strong&gt;Publication Date&lt;/strong&gt;: June 2017&lt;br&gt;
&lt;strong&gt;Published In&lt;/strong&gt;: NeurIPS 2017&lt;br&gt;
&lt;strong&gt;Number of Citations&lt;/strong&gt;: 80,000+&lt;br&gt;
&lt;strong&gt;Link to Paper&lt;/strong&gt;: &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;arXiv.org/attention&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#brief-description&#34;&gt;Brief Description&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#main-topic&#34;&gt;Main Topic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#key-concepts&#34;&gt;Key Concepts&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#1-self-attention-mechanism&#34;&gt;1. Self-Attention Mechanism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#2-multi-head-attention&#34;&gt;2. Multi-Head Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#3-position-wise-feed-forward-networks&#34;&gt;3. Position-wise Feed-Forward Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#4-positional-encoding&#34;&gt;4. Positional Encoding&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#methodology-and-experiments&#34;&gt;Methodology and Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#results-and-practical-impact&#34;&gt;Results and Practical Impact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#limitations&#34;&gt;Limitations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#references-and-related-work&#34;&gt;References and Related Work&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#core-references-cited-by-authors&#34;&gt;Core References&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#subsequent-influential-work-inspired-by-this-paper&#34;&gt;Subsequent Influential Work&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#conclusion-and-takeaways&#34;&gt;Conclusion and Takeaways&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#key-takeaways&#34;&gt;Key Takeaways&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#why-this-paper-still-matters&#34;&gt;Why This Paper Still Matters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/papers/attention-is-all-you-need/#thanks-for-reading&#34;&gt;Thanks for Reading&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;brief-description&#34;&gt;Brief Description&lt;/h2&gt;
&lt;p&gt;This seminal paper introduced the Transformer architecture, which relies entirely on attention mechanisms, revolutionizing natural language processing and laying the foundation for modern generative AI. The architecture has become the backbone of models like GPT, BERT, and their successors.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>AI Weekly – May 5, 2025</title>
      <link>http://localhost:1313/ai-llm-news/ai-weekly-may-5-2025/</link>
      <pubDate>Mon, 05 May 2025 15:24:18 -0300</pubDate>
      
      <guid>http://localhost:1313/ai-llm-news/ai-weekly-may-5-2025/</guid>
      <description>
        
          
            &lt;p&gt;This week brings pivotal advancements in the AI landscape, from redefining developer roles to enhancing search experiences and bolstering national security.&lt;/p&gt;
&lt;h2 id=&#34;1-developers-evolve-into-builders-in-the-ai-era&#34;&gt;1. Developers Evolve into &amp;lsquo;Builders&amp;rsquo; in the AI Era&lt;/h2&gt;




&lt;figure class=&#34;blog-figure&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/images/ai-weekly-may-5-2025_01.png&#34; alt=&#34;Developers evolving into builders in the AI era&#34; class=&#34;blog-image&#34; loading=&#34;lazy&#34;&gt;
    
&lt;/figure&gt;

&lt;p&gt;Varun Mohan, CEO of Windsurf (formerly Codeium), envisions a transformative shift where traditional software developers become &amp;ldquo;builders.&amp;rdquo; This change is driven by AI&amp;rsquo;s capability to democratize software creation, allowing individuals to customize tools using AI assistants, even without formal coding knowledge. Windsurf, an AI coding platform, has gained significant traction, raising $243 million and potentially being acquired by OpenAI for around $3 billion. Mohan emphasizes the rise of &amp;ldquo;vibe coding,&amp;rdquo; a method of generating code via AI prompts that redefines development processes by vastly improving speed and productivity. This evolution encourages a culture of continuous learning and innovation fueled by AI capabilities.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>What People Think AI Engineers Do (vs Reality)</title>
      <link>http://localhost:1313/memes/ai-engineer-meme/</link>
      <pubDate>Fri, 02 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/memes/ai-engineer-meme/</guid>
      <description>
        
          
            &lt;h1 id=&#34;what-people-think-ai-engineers-do-vs-reality&#34;&gt;What People Think AI Engineers Do (vs Reality)&lt;/h1&gt;




&lt;figure class=&#34;blog-figure&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/images/ai_meme_01.png&#34; alt=&#34;AI Engineer Meme&#34; class=&#34;blog-image&#34; loading=&#34;lazy&#34;&gt;
    
&lt;/figure&gt;

&lt;p&gt;We’ve all seen those memes that contrast “What people think I do vs What I really do.”&lt;br&gt;
So I made one for the &lt;strong&gt;AI Engineer&lt;/strong&gt; role, because honestly, the misconceptions are getting out of hand.&lt;/p&gt;
&lt;p&gt;Let’s break them down:&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-my-coworkers-think-i-do&#34;&gt;🧠 What my coworkers think I do&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;“Talk to ChatGPT all day.”&lt;/em&gt;&lt;br&gt;
To be fair, this happens. But it’s not the core of the job. Prompting is not engineering.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Welcome to HiddenLayer</title>
      <link>http://localhost:1313/become-an-ai-expert/welcome/</link>
      <pubDate>Thu, 01 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/become-an-ai-expert/welcome/</guid>
      <description>
        
          
            &lt;h1 id=&#34;welcome-to-hiddenlayer&#34;&gt;Welcome to HiddenLayer&lt;/h1&gt;
&lt;p&gt;This is &lt;strong&gt;HiddenLayer&lt;/strong&gt; — a space where I share, with total clarity and honesty, what it really means to work with Artificial Intelligence in 2025. Here, you won’t find LinkedIn buzzwords or empty hype. Instead, you’ll find:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;My journey as an AI engineer&lt;/li&gt;
&lt;li&gt;Behind-the-scenes of real-world projects&lt;/li&gt;
&lt;li&gt;Insane bugs&lt;/li&gt;
&lt;li&gt;Tough architectural decisions&lt;/li&gt;
&lt;li&gt;Lessons learned through hands-on experience&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of this from someone who’s spent years as a Data Scientist and chose to go deeper into the stack.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
